{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09f253e-b645-4904-9664-6f88b009d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af81800a-95e2-4331-9db4-710d4d48c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.images, self.labels = self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "        label_names = os.listdir(self.data_dir)\n",
    "        \n",
    "        for label in label_names:\n",
    "            label_dir = os.path.join(self.data_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for img_name in os.listdir(label_dir):\n",
    "                    img_path = os.path.join(label_dir, img_name)\n",
    "                    # Read the image\n",
    "                    image = cv2.imread(img_path)\n",
    "                    if image is not None:\n",
    "                        # Resize the image to the fixed size\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "                        if self.transform:\n",
    "                            image = self.transform(image)\n",
    "                        images.append(image)\n",
    "                        labels.append(label)\n",
    "        \n",
    "        # Encode labels\n",
    "        labels = self.label_encoder.fit_transform(labels)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return images, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Specify the directory where your dataset is located\n",
    "data_dir = 'AugmentedAlzheimerDataset'\n",
    "\n",
    "# Define transformations (resize and normalize)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Example normalization\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = CustomDataset(data_dir, transform=data_transform)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883eff68-4f98-4718-9bf7-c8e0567833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN(num_classes=len(dataset.label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdec22b-1d2a-4d38-86f2-cf66d694c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f837aab1-ceef-4c3f-9219-19946dc61288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0726\n",
      "Epoch [2/20], Loss: 0.7870\n",
      "Epoch [3/20], Loss: 0.7037\n",
      "Epoch [4/20], Loss: 0.6339\n",
      "Epoch [5/20], Loss: 0.5857\n",
      "Epoch [6/20], Loss: 0.5490\n",
      "Epoch [7/20], Loss: 0.5262\n",
      "Epoch [8/20], Loss: 0.5028\n",
      "Epoch [9/20], Loss: 0.4856\n",
      "Epoch [10/20], Loss: 0.4663\n",
      "Epoch [11/20], Loss: 0.4481\n",
      "Epoch [12/20], Loss: 0.4338\n",
      "Epoch [13/20], Loss: 0.4247\n",
      "Epoch [14/20], Loss: 0.4051\n",
      "Epoch [15/20], Loss: 0.4005\n",
      "Epoch [16/20], Loss: 0.3921\n",
      "Epoch [17/20], Loss: 0.3815\n",
      "Epoch [18/20], Loss: 0.3738\n",
      "Epoch [19/20], Loss: 0.3670\n",
      "Epoch [20/20], Loss: 0.3598\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a42b487-5068-490d-afdc-237a65193567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {(100 * correct / total):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619338fa-e974-45b3-90d6-5ce36e9be856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ab6db-d0b5-44d9-abc6-76bb94ab4b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
