{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093d9d14-ad74-4fa4-b086-ffb8d9d256f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff6ee91-2d61-41a8-9be1-8b0ef21e62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5004a164-ad70-4661-aca9-e2fb63f3dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d06662-739b-41cb-8632-fc3535083d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b19412-0521-4d87-87db-c0e8440f10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to your training data\n",
    "train_data_path = 'AugmentedAlzheimerDataset'\n",
    "\n",
    "# Load dataset using ImageFolder and split into train and validation\n",
    "train_dataset = ImageFolder(root=train_data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180777ba-d6a6-41ba-975f-51a046b44d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to split 80% for training and 20% for validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = int(0.1 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(train_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c14c73-bc86-42bc-a875-89eec0f4bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ba633e-b09e-43c9-83ea-a1d10d30d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sushant mittal/.cache\\torch\\hub\\huawei-noah_ghostnet_master\n"
     ]
    }
   ],
   "source": [
    "# Load GhostNet model from PyTorch Hub\n",
    "ghostnet = torch.hub.load('huawei-noah/ghostnet', 'ghostnet_1x', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4fd9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model (adding custom layers)\n",
    "class CustomGhostNet(nn.Module):\n",
    "    def __init__(self, original_model, num_classes=4):  # Assuming 4 classes\n",
    "        super(CustomGhostNet, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-1])  # Remove the last layer\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Adjusted dropout rate\n",
    "            nn.Linear(512,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,num_classes),\n",
    "            nn.Softmax(dim=1)  # Apply softmax along the class dimension\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CustomGhostNet(ghostnet, num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39d4a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_activations(model, old_activation, new_activation):\n",
    "    for name, module in model.named_modules():\n",
    "        for child_name, child in module.named_children():\n",
    "            if isinstance(child, old_activation):\n",
    "                setattr(module, child_name, new_activation())\n",
    "    return model\n",
    "\n",
    "# Replace ReLU with LeakyReLU in the entire model\n",
    "model = replace_activations(model, nn.ReLU, nn.PReLU)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac084fe4-683a-4fdd-babc-f31318da72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb81f75-8332-429b-b43f-5bb79ee13989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 1.3485, Train Acc: 34.30%, Val Loss: 1.2838, Val Acc: 40.85%\n",
      "Epoch [2/15], Train Loss: 1.1756, Train Acc: 54.88%, Val Loss: 1.1068, Val Acc: 61.65%\n",
      "Epoch [3/15], Train Loss: 1.0778, Train Acc: 65.52%, Val Loss: 1.0530, Val Acc: 67.83%\n",
      "Epoch [4/15], Train Loss: 1.0312, Train Acc: 70.45%, Val Loss: 1.0084, Val Acc: 73.22%\n",
      "Epoch [5/15], Train Loss: 0.9919, Train Acc: 74.65%, Val Loss: 0.9532, Val Acc: 78.81%\n",
      "Epoch [6/15], Train Loss: 0.9539, Train Acc: 78.78%, Val Loss: 0.9292, Val Acc: 81.14%\n",
      "Epoch [7/15], Train Loss: 0.9249, Train Acc: 81.72%, Val Loss: 0.9085, Val Acc: 83.61%\n",
      "Epoch [8/15], Train Loss: 0.8959, Train Acc: 84.75%, Val Loss: 0.8904, Val Acc: 85.05%\n",
      "Epoch [9/15], Train Loss: 0.8754, Train Acc: 86.76%, Val Loss: 0.8686, Val Acc: 87.73%\n",
      "Epoch [10/15], Train Loss: 0.8564, Train Acc: 88.77%, Val Loss: 0.8740, Val Acc: 86.70%\n",
      "Epoch [11/15], Train Loss: 0.8413, Train Acc: 90.27%, Val Loss: 0.8686, Val Acc: 87.11%\n",
      "Epoch [12/15], Train Loss: 0.8315, Train Acc: 91.20%, Val Loss: 0.8432, Val Acc: 90.14%\n",
      "Epoch [13/15], Train Loss: 0.8178, Train Acc: 92.52%, Val Loss: 0.8265, Val Acc: 91.94%\n",
      "Epoch [14/15], Train Loss: 0.8091, Train Acc: 93.47%, Val Loss: 0.8185, Val Acc: 92.64%\n",
      "Epoch [15/15], Train Loss: 0.7992, Train Acc: 94.46%, Val Loss: 0.8128, Val Acc: 93.17%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct_train / total_train * 100\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_running_loss += val_loss.item()\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / len(val_loader)\n",
    "    val_acc = correct_val / total_val * 100\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {epoch_loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_epoch_loss:.4f}, '\n",
    "          f'Val Acc: {val_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8728c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "             PReLU-3         [-1, 16, 112, 112]               1\n",
      "            Conv2d-4          [-1, 8, 112, 112]             128\n",
      "       BatchNorm2d-5          [-1, 8, 112, 112]              16\n",
      "             PReLU-6          [-1, 8, 112, 112]               1\n",
      "            Conv2d-7          [-1, 8, 112, 112]              72\n",
      "       BatchNorm2d-8          [-1, 8, 112, 112]              16\n",
      "             PReLU-9          [-1, 8, 112, 112]               1\n",
      "      GhostModule-10         [-1, 16, 112, 112]               0\n",
      "           Conv2d-11          [-1, 8, 112, 112]             128\n",
      "      BatchNorm2d-12          [-1, 8, 112, 112]              16\n",
      "           Conv2d-13          [-1, 8, 112, 112]              72\n",
      "      BatchNorm2d-14          [-1, 8, 112, 112]              16\n",
      "      GhostModule-15         [-1, 16, 112, 112]               0\n",
      "  GhostBottleneck-16         [-1, 16, 112, 112]               0\n",
      "           Conv2d-17         [-1, 24, 112, 112]             384\n",
      "      BatchNorm2d-18         [-1, 24, 112, 112]              48\n",
      "            PReLU-19         [-1, 24, 112, 112]               1\n",
      "           Conv2d-20         [-1, 24, 112, 112]             216\n",
      "      BatchNorm2d-21         [-1, 24, 112, 112]              48\n",
      "            PReLU-22         [-1, 24, 112, 112]               1\n",
      "      GhostModule-23         [-1, 48, 112, 112]               0\n",
      "           Conv2d-24           [-1, 48, 56, 56]             432\n",
      "      BatchNorm2d-25           [-1, 48, 56, 56]              96\n",
      "           Conv2d-26           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-27           [-1, 12, 56, 56]              24\n",
      "           Conv2d-28           [-1, 12, 56, 56]             108\n",
      "      BatchNorm2d-29           [-1, 12, 56, 56]              24\n",
      "      GhostModule-30           [-1, 24, 56, 56]               0\n",
      "           Conv2d-31           [-1, 16, 56, 56]             144\n",
      "      BatchNorm2d-32           [-1, 16, 56, 56]              32\n",
      "           Conv2d-33           [-1, 24, 56, 56]             384\n",
      "      BatchNorm2d-34           [-1, 24, 56, 56]              48\n",
      "  GhostBottleneck-35           [-1, 24, 56, 56]               0\n",
      "           Conv2d-36           [-1, 36, 56, 56]             864\n",
      "      BatchNorm2d-37           [-1, 36, 56, 56]              72\n",
      "            PReLU-38           [-1, 36, 56, 56]               1\n",
      "           Conv2d-39           [-1, 36, 56, 56]             324\n",
      "      BatchNorm2d-40           [-1, 36, 56, 56]              72\n",
      "            PReLU-41           [-1, 36, 56, 56]               1\n",
      "      GhostModule-42           [-1, 72, 56, 56]               0\n",
      "           Conv2d-43           [-1, 12, 56, 56]             864\n",
      "      BatchNorm2d-44           [-1, 12, 56, 56]              24\n",
      "           Conv2d-45           [-1, 12, 56, 56]             108\n",
      "      BatchNorm2d-46           [-1, 12, 56, 56]              24\n",
      "      GhostModule-47           [-1, 24, 56, 56]               0\n",
      "  GhostBottleneck-48           [-1, 24, 56, 56]               0\n",
      "           Conv2d-49           [-1, 36, 56, 56]             864\n",
      "      BatchNorm2d-50           [-1, 36, 56, 56]              72\n",
      "            PReLU-51           [-1, 36, 56, 56]               1\n",
      "           Conv2d-52           [-1, 36, 56, 56]             324\n",
      "      BatchNorm2d-53           [-1, 36, 56, 56]              72\n",
      "            PReLU-54           [-1, 36, 56, 56]               1\n",
      "      GhostModule-55           [-1, 72, 56, 56]               0\n",
      "           Conv2d-56           [-1, 72, 28, 28]           1,800\n",
      "      BatchNorm2d-57           [-1, 72, 28, 28]             144\n",
      "AdaptiveAvgPool2d-58             [-1, 72, 1, 1]               0\n",
      "           Conv2d-59             [-1, 20, 1, 1]           1,460\n",
      "            PReLU-60             [-1, 20, 1, 1]               1\n",
      "           Conv2d-61             [-1, 72, 1, 1]           1,512\n",
      "    SqueezeExcite-62           [-1, 72, 28, 28]               0\n",
      "           Conv2d-63           [-1, 20, 28, 28]           1,440\n",
      "      BatchNorm2d-64           [-1, 20, 28, 28]              40\n",
      "           Conv2d-65           [-1, 20, 28, 28]             180\n",
      "      BatchNorm2d-66           [-1, 20, 28, 28]              40\n",
      "      GhostModule-67           [-1, 40, 28, 28]               0\n",
      "           Conv2d-68           [-1, 24, 28, 28]             600\n",
      "      BatchNorm2d-69           [-1, 24, 28, 28]              48\n",
      "           Conv2d-70           [-1, 40, 28, 28]             960\n",
      "      BatchNorm2d-71           [-1, 40, 28, 28]              80\n",
      "  GhostBottleneck-72           [-1, 40, 28, 28]               0\n",
      "           Conv2d-73           [-1, 60, 28, 28]           2,400\n",
      "      BatchNorm2d-74           [-1, 60, 28, 28]             120\n",
      "            PReLU-75           [-1, 60, 28, 28]               1\n",
      "           Conv2d-76           [-1, 60, 28, 28]             540\n",
      "      BatchNorm2d-77           [-1, 60, 28, 28]             120\n",
      "            PReLU-78           [-1, 60, 28, 28]               1\n",
      "      GhostModule-79          [-1, 120, 28, 28]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 120, 1, 1]               0\n",
      "           Conv2d-81             [-1, 32, 1, 1]           3,872\n",
      "            PReLU-82             [-1, 32, 1, 1]               1\n",
      "           Conv2d-83            [-1, 120, 1, 1]           3,960\n",
      "    SqueezeExcite-84          [-1, 120, 28, 28]               0\n",
      "           Conv2d-85           [-1, 20, 28, 28]           2,400\n",
      "      BatchNorm2d-86           [-1, 20, 28, 28]              40\n",
      "           Conv2d-87           [-1, 20, 28, 28]             180\n",
      "      BatchNorm2d-88           [-1, 20, 28, 28]              40\n",
      "      GhostModule-89           [-1, 40, 28, 28]               0\n",
      "  GhostBottleneck-90           [-1, 40, 28, 28]               0\n",
      "           Conv2d-91          [-1, 120, 28, 28]           4,800\n",
      "      BatchNorm2d-92          [-1, 120, 28, 28]             240\n",
      "            PReLU-93          [-1, 120, 28, 28]               1\n",
      "           Conv2d-94          [-1, 120, 28, 28]           1,080\n",
      "      BatchNorm2d-95          [-1, 120, 28, 28]             240\n",
      "            PReLU-96          [-1, 120, 28, 28]               1\n",
      "      GhostModule-97          [-1, 240, 28, 28]               0\n",
      "           Conv2d-98          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-99          [-1, 240, 14, 14]             480\n",
      "          Conv2d-100           [-1, 40, 14, 14]           9,600\n",
      "     BatchNorm2d-101           [-1, 40, 14, 14]              80\n",
      "          Conv2d-102           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-103           [-1, 40, 14, 14]              80\n",
      "     GhostModule-104           [-1, 80, 14, 14]               0\n",
      "          Conv2d-105           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-106           [-1, 40, 14, 14]              80\n",
      "          Conv2d-107           [-1, 80, 14, 14]           3,200\n",
      "     BatchNorm2d-108           [-1, 80, 14, 14]             160\n",
      " GhostBottleneck-109           [-1, 80, 14, 14]               0\n",
      "          Conv2d-110          [-1, 100, 14, 14]           8,000\n",
      "     BatchNorm2d-111          [-1, 100, 14, 14]             200\n",
      "           PReLU-112          [-1, 100, 14, 14]               1\n",
      "          Conv2d-113          [-1, 100, 14, 14]             900\n",
      "     BatchNorm2d-114          [-1, 100, 14, 14]             200\n",
      "           PReLU-115          [-1, 100, 14, 14]               1\n",
      "     GhostModule-116          [-1, 200, 14, 14]               0\n",
      "          Conv2d-117           [-1, 40, 14, 14]           8,000\n",
      "     BatchNorm2d-118           [-1, 40, 14, 14]              80\n",
      "          Conv2d-119           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-120           [-1, 40, 14, 14]              80\n",
      "     GhostModule-121           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-122           [-1, 80, 14, 14]               0\n",
      "          Conv2d-123           [-1, 92, 14, 14]           7,360\n",
      "     BatchNorm2d-124           [-1, 92, 14, 14]             184\n",
      "           PReLU-125           [-1, 92, 14, 14]               1\n",
      "          Conv2d-126           [-1, 92, 14, 14]             828\n",
      "     BatchNorm2d-127           [-1, 92, 14, 14]             184\n",
      "           PReLU-128           [-1, 92, 14, 14]               1\n",
      "     GhostModule-129          [-1, 184, 14, 14]               0\n",
      "          Conv2d-130           [-1, 40, 14, 14]           7,360\n",
      "     BatchNorm2d-131           [-1, 40, 14, 14]              80\n",
      "          Conv2d-132           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-133           [-1, 40, 14, 14]              80\n",
      "     GhostModule-134           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-135           [-1, 80, 14, 14]               0\n",
      "          Conv2d-136           [-1, 92, 14, 14]           7,360\n",
      "     BatchNorm2d-137           [-1, 92, 14, 14]             184\n",
      "           PReLU-138           [-1, 92, 14, 14]               1\n",
      "          Conv2d-139           [-1, 92, 14, 14]             828\n",
      "     BatchNorm2d-140           [-1, 92, 14, 14]             184\n",
      "           PReLU-141           [-1, 92, 14, 14]               1\n",
      "     GhostModule-142          [-1, 184, 14, 14]               0\n",
      "          Conv2d-143           [-1, 40, 14, 14]           7,360\n",
      "     BatchNorm2d-144           [-1, 40, 14, 14]              80\n",
      "          Conv2d-145           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-146           [-1, 40, 14, 14]              80\n",
      "     GhostModule-147           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-148           [-1, 80, 14, 14]               0\n",
      "          Conv2d-149          [-1, 240, 14, 14]          19,200\n",
      "     BatchNorm2d-150          [-1, 240, 14, 14]             480\n",
      "           PReLU-151          [-1, 240, 14, 14]               1\n",
      "          Conv2d-152          [-1, 240, 14, 14]           2,160\n",
      "     BatchNorm2d-153          [-1, 240, 14, 14]             480\n",
      "           PReLU-154          [-1, 240, 14, 14]               1\n",
      "     GhostModule-155          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-156            [-1, 480, 1, 1]               0\n",
      "          Conv2d-157            [-1, 120, 1, 1]          57,720\n",
      "           PReLU-158            [-1, 120, 1, 1]               1\n",
      "          Conv2d-159            [-1, 480, 1, 1]          58,080\n",
      "   SqueezeExcite-160          [-1, 480, 14, 14]               0\n",
      "          Conv2d-161           [-1, 56, 14, 14]          26,880\n",
      "     BatchNorm2d-162           [-1, 56, 14, 14]             112\n",
      "          Conv2d-163           [-1, 56, 14, 14]             504\n",
      "     BatchNorm2d-164           [-1, 56, 14, 14]             112\n",
      "     GhostModule-165          [-1, 112, 14, 14]               0\n",
      "          Conv2d-166           [-1, 80, 14, 14]             720\n",
      "     BatchNorm2d-167           [-1, 80, 14, 14]             160\n",
      "          Conv2d-168          [-1, 112, 14, 14]           8,960\n",
      "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
      " GhostBottleneck-170          [-1, 112, 14, 14]               0\n",
      "          Conv2d-171          [-1, 336, 14, 14]          37,632\n",
      "     BatchNorm2d-172          [-1, 336, 14, 14]             672\n",
      "           PReLU-173          [-1, 336, 14, 14]               1\n",
      "          Conv2d-174          [-1, 336, 14, 14]           3,024\n",
      "     BatchNorm2d-175          [-1, 336, 14, 14]             672\n",
      "           PReLU-176          [-1, 336, 14, 14]               1\n",
      "     GhostModule-177          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179            [-1, 168, 1, 1]         113,064\n",
      "           PReLU-180            [-1, 168, 1, 1]               1\n",
      "          Conv2d-181            [-1, 672, 1, 1]         113,568\n",
      "   SqueezeExcite-182          [-1, 672, 14, 14]               0\n",
      "          Conv2d-183           [-1, 56, 14, 14]          37,632\n",
      "     BatchNorm2d-184           [-1, 56, 14, 14]             112\n",
      "          Conv2d-185           [-1, 56, 14, 14]             504\n",
      "     BatchNorm2d-186           [-1, 56, 14, 14]             112\n",
      "     GhostModule-187          [-1, 112, 14, 14]               0\n",
      " GhostBottleneck-188          [-1, 112, 14, 14]               0\n",
      "          Conv2d-189          [-1, 336, 14, 14]          37,632\n",
      "     BatchNorm2d-190          [-1, 336, 14, 14]             672\n",
      "           PReLU-191          [-1, 336, 14, 14]               1\n",
      "          Conv2d-192          [-1, 336, 14, 14]           3,024\n",
      "     BatchNorm2d-193          [-1, 336, 14, 14]             672\n",
      "           PReLU-194          [-1, 336, 14, 14]               1\n",
      "     GhostModule-195          [-1, 672, 14, 14]               0\n",
      "          Conv2d-196            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-197            [-1, 672, 7, 7]           1,344\n",
      "AdaptiveAvgPool2d-198            [-1, 672, 1, 1]               0\n",
      "          Conv2d-199            [-1, 168, 1, 1]         113,064\n",
      "           PReLU-200            [-1, 168, 1, 1]               1\n",
      "          Conv2d-201            [-1, 672, 1, 1]         113,568\n",
      "   SqueezeExcite-202            [-1, 672, 7, 7]               0\n",
      "          Conv2d-203             [-1, 80, 7, 7]          53,760\n",
      "     BatchNorm2d-204             [-1, 80, 7, 7]             160\n",
      "          Conv2d-205             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-206             [-1, 80, 7, 7]             160\n",
      "     GhostModule-207            [-1, 160, 7, 7]               0\n",
      "          Conv2d-208            [-1, 112, 7, 7]           2,800\n",
      "     BatchNorm2d-209            [-1, 112, 7, 7]             224\n",
      "          Conv2d-210            [-1, 160, 7, 7]          17,920\n",
      "     BatchNorm2d-211            [-1, 160, 7, 7]             320\n",
      " GhostBottleneck-212            [-1, 160, 7, 7]               0\n",
      "          Conv2d-213            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-214            [-1, 480, 7, 7]             960\n",
      "           PReLU-215            [-1, 480, 7, 7]               1\n",
      "          Conv2d-216            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-217            [-1, 480, 7, 7]             960\n",
      "           PReLU-218            [-1, 480, 7, 7]               1\n",
      "     GhostModule-219            [-1, 960, 7, 7]               0\n",
      "          Conv2d-220             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-221             [-1, 80, 7, 7]             160\n",
      "          Conv2d-222             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-223             [-1, 80, 7, 7]             160\n",
      "     GhostModule-224            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-225            [-1, 160, 7, 7]               0\n",
      "          Conv2d-226            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-227            [-1, 480, 7, 7]             960\n",
      "           PReLU-228            [-1, 480, 7, 7]               1\n",
      "          Conv2d-229            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-230            [-1, 480, 7, 7]             960\n",
      "           PReLU-231            [-1, 480, 7, 7]               1\n",
      "     GhostModule-232            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-233            [-1, 960, 1, 1]               0\n",
      "          Conv2d-234            [-1, 240, 1, 1]         230,640\n",
      "           PReLU-235            [-1, 240, 1, 1]               1\n",
      "          Conv2d-236            [-1, 960, 1, 1]         231,360\n",
      "   SqueezeExcite-237            [-1, 960, 7, 7]               0\n",
      "          Conv2d-238             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-239             [-1, 80, 7, 7]             160\n",
      "          Conv2d-240             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-241             [-1, 80, 7, 7]             160\n",
      "     GhostModule-242            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-243            [-1, 160, 7, 7]               0\n",
      "          Conv2d-244            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-245            [-1, 480, 7, 7]             960\n",
      "           PReLU-246            [-1, 480, 7, 7]               1\n",
      "          Conv2d-247            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-248            [-1, 480, 7, 7]             960\n",
      "           PReLU-249            [-1, 480, 7, 7]               1\n",
      "     GhostModule-250            [-1, 960, 7, 7]               0\n",
      "          Conv2d-251             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-252             [-1, 80, 7, 7]             160\n",
      "          Conv2d-253             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-254             [-1, 80, 7, 7]             160\n",
      "     GhostModule-255            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-256            [-1, 160, 7, 7]               0\n",
      "          Conv2d-257            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-258            [-1, 480, 7, 7]             960\n",
      "           PReLU-259            [-1, 480, 7, 7]               1\n",
      "          Conv2d-260            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-261            [-1, 480, 7, 7]             960\n",
      "           PReLU-262            [-1, 480, 7, 7]               1\n",
      "     GhostModule-263            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-264            [-1, 960, 1, 1]               0\n",
      "          Conv2d-265            [-1, 240, 1, 1]         230,640\n",
      "           PReLU-266            [-1, 240, 1, 1]               1\n",
      "          Conv2d-267            [-1, 960, 1, 1]         231,360\n",
      "   SqueezeExcite-268            [-1, 960, 7, 7]               0\n",
      "          Conv2d-269             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-270             [-1, 80, 7, 7]             160\n",
      "          Conv2d-271             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-272             [-1, 80, 7, 7]             160\n",
      "     GhostModule-273            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-274            [-1, 160, 7, 7]               0\n",
      "          Conv2d-275            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-276            [-1, 960, 7, 7]           1,920\n",
      "           PReLU-277            [-1, 960, 7, 7]               1\n",
      "       ConvBnAct-278            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-279            [-1, 960, 1, 1]               0\n",
      "          Conv2d-280           [-1, 1280, 1, 1]       1,230,080\n",
      "           PReLU-281           [-1, 1280, 1, 1]               1\n",
      "         Flatten-282                 [-1, 1280]               0\n",
      "          Linear-283                  [-1, 512]         655,872\n",
      "           PReLU-284                  [-1, 512]               1\n",
      "         Dropout-285                  [-1, 512]               0\n",
      "          Linear-286                  [-1, 128]          65,664\n",
      "           PReLU-287                  [-1, 128]               1\n",
      "          Linear-288                   [-1, 32]           4,128\n",
      "           PReLU-289                   [-1, 32]               1\n",
      "          Linear-290                    [-1, 4]             132\n",
      "         Softmax-291                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 4,627,349\n",
      "Trainable params: 4,627,349\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 102.22\n",
      "Params size (MB): 17.65\n",
      "Estimated Total Size (MB): 120.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c16ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Testing Accuracy: 93.47%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = correct / total * 100\n",
    "print(f'Final Testing Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0909e37-74d9-4009-84c4-e8189c258a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'ghostnet_softmax_15epochs_93point47_test_acc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c310767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "              ReLU-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4          [-1, 8, 112, 112]             128\n",
      "       BatchNorm2d-5          [-1, 8, 112, 112]              16\n",
      "              ReLU-6          [-1, 8, 112, 112]               0\n",
      "            Conv2d-7          [-1, 8, 112, 112]              72\n",
      "       BatchNorm2d-8          [-1, 8, 112, 112]              16\n",
      "              ReLU-9          [-1, 8, 112, 112]               0\n",
      "      GhostModule-10         [-1, 16, 112, 112]               0\n",
      "           Conv2d-11          [-1, 8, 112, 112]             128\n",
      "      BatchNorm2d-12          [-1, 8, 112, 112]              16\n",
      "           Conv2d-13          [-1, 8, 112, 112]              72\n",
      "      BatchNorm2d-14          [-1, 8, 112, 112]              16\n",
      "      GhostModule-15         [-1, 16, 112, 112]               0\n",
      "  GhostBottleneck-16         [-1, 16, 112, 112]               0\n",
      "           Conv2d-17         [-1, 24, 112, 112]             384\n",
      "      BatchNorm2d-18         [-1, 24, 112, 112]              48\n",
      "             ReLU-19         [-1, 24, 112, 112]               0\n",
      "           Conv2d-20         [-1, 24, 112, 112]             216\n",
      "      BatchNorm2d-21         [-1, 24, 112, 112]              48\n",
      "             ReLU-22         [-1, 24, 112, 112]               0\n",
      "      GhostModule-23         [-1, 48, 112, 112]               0\n",
      "           Conv2d-24           [-1, 48, 56, 56]             432\n",
      "      BatchNorm2d-25           [-1, 48, 56, 56]              96\n",
      "           Conv2d-26           [-1, 12, 56, 56]             576\n",
      "      BatchNorm2d-27           [-1, 12, 56, 56]              24\n",
      "           Conv2d-28           [-1, 12, 56, 56]             108\n",
      "      BatchNorm2d-29           [-1, 12, 56, 56]              24\n",
      "      GhostModule-30           [-1, 24, 56, 56]               0\n",
      "           Conv2d-31           [-1, 16, 56, 56]             144\n",
      "      BatchNorm2d-32           [-1, 16, 56, 56]              32\n",
      "           Conv2d-33           [-1, 24, 56, 56]             384\n",
      "      BatchNorm2d-34           [-1, 24, 56, 56]              48\n",
      "  GhostBottleneck-35           [-1, 24, 56, 56]               0\n",
      "           Conv2d-36           [-1, 36, 56, 56]             864\n",
      "      BatchNorm2d-37           [-1, 36, 56, 56]              72\n",
      "             ReLU-38           [-1, 36, 56, 56]               0\n",
      "           Conv2d-39           [-1, 36, 56, 56]             324\n",
      "      BatchNorm2d-40           [-1, 36, 56, 56]              72\n",
      "             ReLU-41           [-1, 36, 56, 56]               0\n",
      "      GhostModule-42           [-1, 72, 56, 56]               0\n",
      "           Conv2d-43           [-1, 12, 56, 56]             864\n",
      "      BatchNorm2d-44           [-1, 12, 56, 56]              24\n",
      "           Conv2d-45           [-1, 12, 56, 56]             108\n",
      "      BatchNorm2d-46           [-1, 12, 56, 56]              24\n",
      "      GhostModule-47           [-1, 24, 56, 56]               0\n",
      "  GhostBottleneck-48           [-1, 24, 56, 56]               0\n",
      "           Conv2d-49           [-1, 36, 56, 56]             864\n",
      "      BatchNorm2d-50           [-1, 36, 56, 56]              72\n",
      "             ReLU-51           [-1, 36, 56, 56]               0\n",
      "           Conv2d-52           [-1, 36, 56, 56]             324\n",
      "      BatchNorm2d-53           [-1, 36, 56, 56]              72\n",
      "             ReLU-54           [-1, 36, 56, 56]               0\n",
      "      GhostModule-55           [-1, 72, 56, 56]               0\n",
      "           Conv2d-56           [-1, 72, 28, 28]           1,800\n",
      "      BatchNorm2d-57           [-1, 72, 28, 28]             144\n",
      "AdaptiveAvgPool2d-58             [-1, 72, 1, 1]               0\n",
      "           Conv2d-59             [-1, 20, 1, 1]           1,460\n",
      "             ReLU-60             [-1, 20, 1, 1]               0\n",
      "           Conv2d-61             [-1, 72, 1, 1]           1,512\n",
      "    SqueezeExcite-62           [-1, 72, 28, 28]               0\n",
      "           Conv2d-63           [-1, 20, 28, 28]           1,440\n",
      "      BatchNorm2d-64           [-1, 20, 28, 28]              40\n",
      "           Conv2d-65           [-1, 20, 28, 28]             180\n",
      "      BatchNorm2d-66           [-1, 20, 28, 28]              40\n",
      "      GhostModule-67           [-1, 40, 28, 28]               0\n",
      "           Conv2d-68           [-1, 24, 28, 28]             600\n",
      "      BatchNorm2d-69           [-1, 24, 28, 28]              48\n",
      "           Conv2d-70           [-1, 40, 28, 28]             960\n",
      "      BatchNorm2d-71           [-1, 40, 28, 28]              80\n",
      "  GhostBottleneck-72           [-1, 40, 28, 28]               0\n",
      "           Conv2d-73           [-1, 60, 28, 28]           2,400\n",
      "      BatchNorm2d-74           [-1, 60, 28, 28]             120\n",
      "             ReLU-75           [-1, 60, 28, 28]               0\n",
      "           Conv2d-76           [-1, 60, 28, 28]             540\n",
      "      BatchNorm2d-77           [-1, 60, 28, 28]             120\n",
      "             ReLU-78           [-1, 60, 28, 28]               0\n",
      "      GhostModule-79          [-1, 120, 28, 28]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 120, 1, 1]               0\n",
      "           Conv2d-81             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-82             [-1, 32, 1, 1]               0\n",
      "           Conv2d-83            [-1, 120, 1, 1]           3,960\n",
      "    SqueezeExcite-84          [-1, 120, 28, 28]               0\n",
      "           Conv2d-85           [-1, 20, 28, 28]           2,400\n",
      "      BatchNorm2d-86           [-1, 20, 28, 28]              40\n",
      "           Conv2d-87           [-1, 20, 28, 28]             180\n",
      "      BatchNorm2d-88           [-1, 20, 28, 28]              40\n",
      "      GhostModule-89           [-1, 40, 28, 28]               0\n",
      "  GhostBottleneck-90           [-1, 40, 28, 28]               0\n",
      "           Conv2d-91          [-1, 120, 28, 28]           4,800\n",
      "      BatchNorm2d-92          [-1, 120, 28, 28]             240\n",
      "             ReLU-93          [-1, 120, 28, 28]               0\n",
      "           Conv2d-94          [-1, 120, 28, 28]           1,080\n",
      "      BatchNorm2d-95          [-1, 120, 28, 28]             240\n",
      "             ReLU-96          [-1, 120, 28, 28]               0\n",
      "      GhostModule-97          [-1, 240, 28, 28]               0\n",
      "           Conv2d-98          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-99          [-1, 240, 14, 14]             480\n",
      "          Conv2d-100           [-1, 40, 14, 14]           9,600\n",
      "     BatchNorm2d-101           [-1, 40, 14, 14]              80\n",
      "          Conv2d-102           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-103           [-1, 40, 14, 14]              80\n",
      "     GhostModule-104           [-1, 80, 14, 14]               0\n",
      "          Conv2d-105           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-106           [-1, 40, 14, 14]              80\n",
      "          Conv2d-107           [-1, 80, 14, 14]           3,200\n",
      "     BatchNorm2d-108           [-1, 80, 14, 14]             160\n",
      " GhostBottleneck-109           [-1, 80, 14, 14]               0\n",
      "          Conv2d-110          [-1, 100, 14, 14]           8,000\n",
      "     BatchNorm2d-111          [-1, 100, 14, 14]             200\n",
      "            ReLU-112          [-1, 100, 14, 14]               0\n",
      "          Conv2d-113          [-1, 100, 14, 14]             900\n",
      "     BatchNorm2d-114          [-1, 100, 14, 14]             200\n",
      "            ReLU-115          [-1, 100, 14, 14]               0\n",
      "     GhostModule-116          [-1, 200, 14, 14]               0\n",
      "          Conv2d-117           [-1, 40, 14, 14]           8,000\n",
      "     BatchNorm2d-118           [-1, 40, 14, 14]              80\n",
      "          Conv2d-119           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-120           [-1, 40, 14, 14]              80\n",
      "     GhostModule-121           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-122           [-1, 80, 14, 14]               0\n",
      "          Conv2d-123           [-1, 92, 14, 14]           7,360\n",
      "     BatchNorm2d-124           [-1, 92, 14, 14]             184\n",
      "            ReLU-125           [-1, 92, 14, 14]               0\n",
      "          Conv2d-126           [-1, 92, 14, 14]             828\n",
      "     BatchNorm2d-127           [-1, 92, 14, 14]             184\n",
      "            ReLU-128           [-1, 92, 14, 14]               0\n",
      "     GhostModule-129          [-1, 184, 14, 14]               0\n",
      "          Conv2d-130           [-1, 40, 14, 14]           7,360\n",
      "     BatchNorm2d-131           [-1, 40, 14, 14]              80\n",
      "          Conv2d-132           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-133           [-1, 40, 14, 14]              80\n",
      "     GhostModule-134           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-135           [-1, 80, 14, 14]               0\n",
      "          Conv2d-136           [-1, 92, 14, 14]           7,360\n",
      "     BatchNorm2d-137           [-1, 92, 14, 14]             184\n",
      "            ReLU-138           [-1, 92, 14, 14]               0\n",
      "          Conv2d-139           [-1, 92, 14, 14]             828\n",
      "     BatchNorm2d-140           [-1, 92, 14, 14]             184\n",
      "            ReLU-141           [-1, 92, 14, 14]               0\n",
      "     GhostModule-142          [-1, 184, 14, 14]               0\n",
      "          Conv2d-143           [-1, 40, 14, 14]           7,360\n",
      "     BatchNorm2d-144           [-1, 40, 14, 14]              80\n",
      "          Conv2d-145           [-1, 40, 14, 14]             360\n",
      "     BatchNorm2d-146           [-1, 40, 14, 14]              80\n",
      "     GhostModule-147           [-1, 80, 14, 14]               0\n",
      " GhostBottleneck-148           [-1, 80, 14, 14]               0\n",
      "          Conv2d-149          [-1, 240, 14, 14]          19,200\n",
      "     BatchNorm2d-150          [-1, 240, 14, 14]             480\n",
      "            ReLU-151          [-1, 240, 14, 14]               0\n",
      "          Conv2d-152          [-1, 240, 14, 14]           2,160\n",
      "     BatchNorm2d-153          [-1, 240, 14, 14]             480\n",
      "            ReLU-154          [-1, 240, 14, 14]               0\n",
      "     GhostModule-155          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-156            [-1, 480, 1, 1]               0\n",
      "          Conv2d-157            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-158            [-1, 120, 1, 1]               0\n",
      "          Conv2d-159            [-1, 480, 1, 1]          58,080\n",
      "   SqueezeExcite-160          [-1, 480, 14, 14]               0\n",
      "          Conv2d-161           [-1, 56, 14, 14]          26,880\n",
      "     BatchNorm2d-162           [-1, 56, 14, 14]             112\n",
      "          Conv2d-163           [-1, 56, 14, 14]             504\n",
      "     BatchNorm2d-164           [-1, 56, 14, 14]             112\n",
      "     GhostModule-165          [-1, 112, 14, 14]               0\n",
      "          Conv2d-166           [-1, 80, 14, 14]             720\n",
      "     BatchNorm2d-167           [-1, 80, 14, 14]             160\n",
      "          Conv2d-168          [-1, 112, 14, 14]           8,960\n",
      "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
      " GhostBottleneck-170          [-1, 112, 14, 14]               0\n",
      "          Conv2d-171          [-1, 336, 14, 14]          37,632\n",
      "     BatchNorm2d-172          [-1, 336, 14, 14]             672\n",
      "            ReLU-173          [-1, 336, 14, 14]               0\n",
      "          Conv2d-174          [-1, 336, 14, 14]           3,024\n",
      "     BatchNorm2d-175          [-1, 336, 14, 14]             672\n",
      "            ReLU-176          [-1, 336, 14, 14]               0\n",
      "     GhostModule-177          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-180            [-1, 168, 1, 1]               0\n",
      "          Conv2d-181            [-1, 672, 1, 1]         113,568\n",
      "   SqueezeExcite-182          [-1, 672, 14, 14]               0\n",
      "          Conv2d-183           [-1, 56, 14, 14]          37,632\n",
      "     BatchNorm2d-184           [-1, 56, 14, 14]             112\n",
      "          Conv2d-185           [-1, 56, 14, 14]             504\n",
      "     BatchNorm2d-186           [-1, 56, 14, 14]             112\n",
      "     GhostModule-187          [-1, 112, 14, 14]               0\n",
      " GhostBottleneck-188          [-1, 112, 14, 14]               0\n",
      "          Conv2d-189          [-1, 336, 14, 14]          37,632\n",
      "     BatchNorm2d-190          [-1, 336, 14, 14]             672\n",
      "            ReLU-191          [-1, 336, 14, 14]               0\n",
      "          Conv2d-192          [-1, 336, 14, 14]           3,024\n",
      "     BatchNorm2d-193          [-1, 336, 14, 14]             672\n",
      "            ReLU-194          [-1, 336, 14, 14]               0\n",
      "     GhostModule-195          [-1, 672, 14, 14]               0\n",
      "          Conv2d-196            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-197            [-1, 672, 7, 7]           1,344\n",
      "AdaptiveAvgPool2d-198            [-1, 672, 1, 1]               0\n",
      "          Conv2d-199            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-200            [-1, 168, 1, 1]               0\n",
      "          Conv2d-201            [-1, 672, 1, 1]         113,568\n",
      "   SqueezeExcite-202            [-1, 672, 7, 7]               0\n",
      "          Conv2d-203             [-1, 80, 7, 7]          53,760\n",
      "     BatchNorm2d-204             [-1, 80, 7, 7]             160\n",
      "          Conv2d-205             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-206             [-1, 80, 7, 7]             160\n",
      "     GhostModule-207            [-1, 160, 7, 7]               0\n",
      "          Conv2d-208            [-1, 112, 7, 7]           2,800\n",
      "     BatchNorm2d-209            [-1, 112, 7, 7]             224\n",
      "          Conv2d-210            [-1, 160, 7, 7]          17,920\n",
      "     BatchNorm2d-211            [-1, 160, 7, 7]             320\n",
      " GhostBottleneck-212            [-1, 160, 7, 7]               0\n",
      "          Conv2d-213            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-214            [-1, 480, 7, 7]             960\n",
      "            ReLU-215            [-1, 480, 7, 7]               0\n",
      "          Conv2d-216            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-217            [-1, 480, 7, 7]             960\n",
      "            ReLU-218            [-1, 480, 7, 7]               0\n",
      "     GhostModule-219            [-1, 960, 7, 7]               0\n",
      "          Conv2d-220             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-221             [-1, 80, 7, 7]             160\n",
      "          Conv2d-222             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-223             [-1, 80, 7, 7]             160\n",
      "     GhostModule-224            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-225            [-1, 160, 7, 7]               0\n",
      "          Conv2d-226            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-227            [-1, 480, 7, 7]             960\n",
      "            ReLU-228            [-1, 480, 7, 7]               0\n",
      "          Conv2d-229            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-230            [-1, 480, 7, 7]             960\n",
      "            ReLU-231            [-1, 480, 7, 7]               0\n",
      "     GhostModule-232            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-233            [-1, 960, 1, 1]               0\n",
      "          Conv2d-234            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-235            [-1, 240, 1, 1]               0\n",
      "          Conv2d-236            [-1, 960, 1, 1]         231,360\n",
      "   SqueezeExcite-237            [-1, 960, 7, 7]               0\n",
      "          Conv2d-238             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-239             [-1, 80, 7, 7]             160\n",
      "          Conv2d-240             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-241             [-1, 80, 7, 7]             160\n",
      "     GhostModule-242            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-243            [-1, 160, 7, 7]               0\n",
      "          Conv2d-244            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-245            [-1, 480, 7, 7]             960\n",
      "            ReLU-246            [-1, 480, 7, 7]               0\n",
      "          Conv2d-247            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-248            [-1, 480, 7, 7]             960\n",
      "            ReLU-249            [-1, 480, 7, 7]               0\n",
      "     GhostModule-250            [-1, 960, 7, 7]               0\n",
      "          Conv2d-251             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-252             [-1, 80, 7, 7]             160\n",
      "          Conv2d-253             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-254             [-1, 80, 7, 7]             160\n",
      "     GhostModule-255            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-256            [-1, 160, 7, 7]               0\n",
      "          Conv2d-257            [-1, 480, 7, 7]          76,800\n",
      "     BatchNorm2d-258            [-1, 480, 7, 7]             960\n",
      "            ReLU-259            [-1, 480, 7, 7]               0\n",
      "          Conv2d-260            [-1, 480, 7, 7]           4,320\n",
      "     BatchNorm2d-261            [-1, 480, 7, 7]             960\n",
      "            ReLU-262            [-1, 480, 7, 7]               0\n",
      "     GhostModule-263            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-264            [-1, 960, 1, 1]               0\n",
      "          Conv2d-265            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-266            [-1, 240, 1, 1]               0\n",
      "          Conv2d-267            [-1, 960, 1, 1]         231,360\n",
      "   SqueezeExcite-268            [-1, 960, 7, 7]               0\n",
      "          Conv2d-269             [-1, 80, 7, 7]          76,800\n",
      "     BatchNorm2d-270             [-1, 80, 7, 7]             160\n",
      "          Conv2d-271             [-1, 80, 7, 7]             720\n",
      "     BatchNorm2d-272             [-1, 80, 7, 7]             160\n",
      "     GhostModule-273            [-1, 160, 7, 7]               0\n",
      " GhostBottleneck-274            [-1, 160, 7, 7]               0\n",
      "          Conv2d-275            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-276            [-1, 960, 7, 7]           1,920\n",
      "            ReLU-277            [-1, 960, 7, 7]               0\n",
      "       ConvBnAct-278            [-1, 960, 7, 7]               0\n",
      "AdaptiveAvgPool2d-279            [-1, 960, 1, 1]               0\n",
      "          Conv2d-280           [-1, 1280, 1, 1]       1,230,080\n",
      "            ReLU-281           [-1, 1280, 1, 1]               0\n",
      "         Flatten-282                 [-1, 1280]               0\n",
      "          Linear-283                  [-1, 512]         655,872\n",
      "            ReLU-284                  [-1, 512]               0\n",
      "         Dropout-285                  [-1, 512]               0\n",
      "          Linear-286                    [-1, 4]           2,052\n",
      "================================================================\n",
      "Total params: 4,559,432\n",
      "Trainable params: 4,559,432\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 102.21\n",
      "Params size (MB): 17.39\n",
      "Estimated Total Size (MB): 120.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b076f82-c6e7-46d3-b88f-6a93995f6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'OriginalDataset' \n",
    "test_dataset = ImageFolder(root=test_data_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f9b4696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d29b7490-41cf-483a-aa77-fcbaa8efcd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 96.88%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = correct / total * 100\n",
    "print(f'Final Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd269d45-46a1-4214-bdb7-87fab75bd571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = correct / total * 100\n",
    "print(f'Final Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b01317-c8ec-427a-91dd-359de963f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
